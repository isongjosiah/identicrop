{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "True_gaze.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isongjosiah/identicrop/blob/main/True_gaze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X2mm9FdDRz8W"
      },
      "source": [
        "# Introduction\n",
        "A bunch of fancy stuff here to introduce the reader to the project\n",
        "Lorem Ipsum stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NYB9Vh9Rz8n"
      },
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import joblib\n",
        "from skimage.transform import resize, rotate\n",
        "from skimage import exposure\n",
        "from skimage.feature import hog\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy import ndimage\n",
        "from skimage import io as skio\n",
        "from skimage import filters\n",
        "from scipy import misc\n",
        "from skimage import util\n",
        " "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfoeA7CrlSrJ"
      },
      "source": [
        "# Global variables and functions\n",
        "\n",
        "# Variables\n",
        "base_path = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "\n",
        "# Functions \n",
        "def make_folder(path):\n",
        "  \"\"\" Check if a folder exists, if it doesn't exist create one in the given path\n",
        "  Args:\n",
        "    path [str]: path where the folder needs to be crerated\n",
        "  \"\"\"\n",
        "\n",
        "  if not os.path.exists(os.path.join(path)):\n",
        "    print(f'[INFO] Creating new folder {path}...')\n",
        "    os.makedirs(os.path.join(path))\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLoyIQYQPA35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860078b2-a2dc-4d26-fd3f-aa56fc375cd9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZRAurloN2iN"
      },
      "source": [
        "'''\r\n",
        "Gray images are resized to be of equal size and proportion, so as to reduce computation time.\r\n",
        "\r\n",
        "'''\r\n",
        "def remove_background(image_rgb):\r\n",
        "  height, width = image_rgb.shape[:2]\r\n",
        "\r\n",
        "  rectangle = (10,10,width-30,height-30)\r\n",
        "  # Create initial mask\r\n",
        "  mask = np.zeros(image_rgb.shape[:2], np.uint8)\r\n",
        "\r\n",
        "  # Create temporary arrays used by grabCut\r\n",
        "  bgdModel = np.zeros((1, 65), np.float64)\r\n",
        "  fgdModel = np.zeros((1, 65), np.float64)\r\n",
        "\r\n",
        "  # Run grabCut\r\n",
        "  cv2.grabCut(image_rgb, # Our image\r\n",
        "              mask, # The Mask\r\n",
        "              rectangle, # Our rectangle\r\n",
        "              bgdModel, # Temporary array for background\r\n",
        "              fgdModel, # Temporary array for background\r\n",
        "              5, # Number of iterations\r\n",
        "              cv2.GC_INIT_WITH_RECT) # Initiative using our rectangle\r\n",
        "\r\n",
        "  # Create mask where sure and likely backgrounds set to 0, otherwise 1\r\n",
        "  mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\r\n",
        "\r\n",
        "  # Multiply image with new mask to subtract background\r\n",
        "  image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]\r\n",
        "\r\n",
        "  return image_rgb_nobg"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0etG7umlWRzF"
      },
      "source": [
        "# Image processing code\n",
        "def resize_image(image):\n",
        "  \"\"\"\n",
        "  Resizes the image to a 100 by 100.\n",
        "  Args:\n",
        "    image (numpy array): Array of image pixels.\n",
        "\n",
        "  Returns:\n",
        "    (numpy array): Resized image\n",
        "  \"\"\"\n",
        "  image = resize(image, (100,100))\n",
        "  return image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDcpWyW0dCxm"
      },
      "source": [
        "def threshold(image, value):\r\n",
        "  #image = read_image(image)\r\n",
        "  image = image > value\r\n",
        "  return image\r\n",
        "\r\n",
        "def get_threshold_image(image):\r\n",
        "\r\n",
        "  #converts image np array to grey scale\r\n",
        "  r, g, b = image[:,:,0], image[:,:,1], image[:,:,2]\r\n",
        "  gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\r\n",
        "  i = np.dot(image[...,:3], [0.299, 0.587, 0.114])\r\n",
        "\r\n",
        "  im_th = threshold(i, 0.2)\r\n",
        "  \r\n",
        "  new_image = util.img_as_ubyte(im_th, force_copy=False)\r\n",
        "\r\n",
        "  filled_image = ndimage.binary_fill_holes(new_image)\r\n",
        "  \r\n",
        "  return new_image\r\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0rZLUvma6fH"
      },
      "source": [
        "def process_images(image):\n",
        "  # image_bgr = cv2.imread(image_path)\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_no_bgr = remove_background(image_rgb)\n",
        "  resized_image = resize_image(image_no_bgr)\n",
        "  image_thresh = get_threshold_image(resized_image)\n",
        "\n",
        "  return image_thresh"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lGWNkjLkRz8v"
      },
      "source": [
        "#specify image path\n",
        "colored_img_path = \"/content/drive/MyDrive/dataset\"\n",
        "filenames = sorted(os.listdir(colored_img_path))\n",
        "\n",
        "\n",
        "def get_image_path(path, foldername=\"\"):\n",
        "    \"\"\"\n",
        "    The function reads images from a location, specified by the path returning an array containing the images in that\n",
        "    location\n",
        "    :param path: the location of the data.\n",
        "    :param foldername: this by default is an empty string but can be used if the path contains multiple folders you\n",
        "    you can then parse using a for loop and changing the value of the parameter at every iteration\n",
        "    :return: an array of images in the path/filename directory\n",
        "    \"\"\"\n",
        "    images = sorted([os.path.join(path, foldername, file) for file in os.listdir(os.path.join(path, foldername))])\n",
        "    return images\n",
        "\n",
        "\n",
        "def get_label(file_name):\n",
        "  label = file_name.replace(\"___\", \" \")\n",
        "  label = label.replace(\"_\", \" \")\n",
        "  return label\n",
        "\n",
        "\n",
        "def load_dataset(path, filenames):\n",
        "    \"\"\"\n",
        "    load_dataset loads all of the images in the plantvillage dataset storing them in a dictionary with keys representing\n",
        "    the foldernames and the values are arrays containing the images in the folder\n",
        "    :param path: the location of the data\n",
        "    :param filenames: a list of the folders in the path. This can be obtained by running sorted(os.listdir(path))\n",
        "    :return: a dictionary with keys identifying the crops and diseased state(healthy or the type of diseases)and values\n",
        "    which are arrays containing the images in that folder\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for i in filenames:\n",
        "        # Ignore ipynb checkpoints and any other plant except apple\n",
        "        if i == '.ipynb_checkpoints' or \"Apple\" not in i :\n",
        "          continue\n",
        "        img_arr = get_image_path(path, i)\n",
        "        for img in img_arr:\n",
        "          img = plt.imread(img)\n",
        "          img = process_images(img)\n",
        "          images.append(img)\n",
        "          labels.append(get_label(i))\n",
        "    img_arr = np.array(images)\n",
        "    label_arr = np.array(labels)\n",
        "          \n",
        "    return images,labels"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY-nmxWr5pCf"
      },
      "source": [
        "def hog_feature(image):\r\n",
        "  \"\"\"\r\n",
        "  Extract HOG feature descriptors from the image\r\n",
        "\r\n",
        "  Args: \r\n",
        "    image (numpy array): Array of image pixels.\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    (numpy array): Feature descriptors\r\n",
        "  \"\"\"\r\n",
        "  return hog(image)\r\n",
        "\r\n",
        "def extract_feature():\r\n",
        "  \"\"\"\r\n",
        "  Load images and extract HOG feature desscriptors.\r\n",
        "  \"\"\"\r\n",
        "  X_train = np.load(os.path.join(base_path, \"augment/imageaugment_input.npy\"))\r\n",
        "  print(\"===TRAIN DATA===\")\r\n",
        "  print(len(X_train))\r\n",
        "\r\n",
        "  X_test = np.load(os.path.join(base_path, \"test/imagetest_input.npy\"))\r\n",
        "  print(\"===TEST DATA===\")\r\n",
        "  print(len(X_test))\r\n",
        "\r\n",
        "  print(\"Extracting HOG features...\")\r\n",
        "  RF_train = np.zeros([len(X_train), 8100])\r\n",
        "  for i in range(len(X_train)):\r\n",
        "    RF_train[i] = hog_feature(X_train[i])\r\n",
        "  print(\"FEATURE DESCRIPTORS\")\r\n",
        "  print(len(RF_train))\r\n",
        "\r\n",
        "  RF_test = np.zeros([len(X_test), 8100])\r\n",
        "  for i in range(len(X_test)):\r\n",
        "    RF_test[i] = hog_feature(X_test[i])\r\n",
        "  print(len(RF_test))\r\n",
        "\r\n",
        "  # Save data\r\n",
        "  make_folder(os.path.join(base_path, \"processed\"))\r\n",
        "  np.save(os.path.join(base_path, \"processed/imagetrainHOG_input.npy\"), RF_train)\r\n",
        "  np.save(os.path.join(base_path, \"processed/imagetestHOG_input.npy\"), RF_test)\r\n",
        "\r\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbLY4uvvJCuq"
      },
      "source": [
        "# Data Augmentation\n",
        "def random_rotation(img):\n",
        "  \"\"\"\n",
        "  Randomly rotate the image.\n",
        "  The function picks a random degree of rotation between 25% on the \n",
        "  left and 25% on the right\n",
        "\n",
        "  Args:\n",
        "    img (numpy array): Array of image pixel to rotate\n",
        "\n",
        "  Returns:\n",
        "    (numpy array): Rotated image.\n",
        "  \"\"\"\n",
        "  random_deg = random.uniform(-25, 25)\n",
        "  return rotate(img, random_deg, preserve_range=True).astype(np.uint8)\n",
        "\n",
        "def horizontal_flip(img):\n",
        "  \"\"\"\n",
        "  Flip the image horizontally\n",
        "  Args:\n",
        "    img (numpy array): Array of image pixels.\n",
        "\n",
        "  Returns:\n",
        "    (numpy array): Flipped image.\n",
        "  \"\"\"\n",
        "  return np.fliplr(img)\n",
        "\n",
        "def vertical_flip(img):\n",
        "  \"\"\"\n",
        "  Flip the image vertically\n",
        "  Args:\n",
        "    img (numpy array): Array of image pixels\n",
        "  Returns:\n",
        "    (numpy array): Flipped image.\n",
        "  \"\"\"\n",
        "  return np.flipud(img)\n",
        "\n",
        "def gama(img):\n",
        "  \"\"\"\n",
        "  Perform gamma correction of the image\n",
        "\n",
        "  Args:\n",
        "    img (numpy arrayy): Array of image pixes\n",
        "\n",
        "  Returns:\n",
        "    (numpy array): Enhanced image.\n",
        "  \"\"\"\n",
        "  return exposure.adjust_gamma(img, gamma=0.4, gain=0.9)\n",
        "\n",
        "\n",
        "def intensity(img):\n",
        "    \"\"\" \n",
        "    Change the intensity of the image.\n",
        "    Args:\n",
        "        img (numpy array): Array of image pixels.\n",
        "    Returns:\n",
        "        (numpy array): Enhanced image.\n",
        "    \"\"\"\n",
        "    v_min, v_max = np.percentile(img, (0.2, 99.8))\n",
        "    if np.abs(v_max - v_min) < 1e-3:\n",
        "        v_max += 1e-3\n",
        "    return exposure.rescale_intensity(img, in_range=(v_min, v_max))\n",
        "\n",
        "def augment_image(img, label):\n",
        "  \"\"\"\n",
        "  Performs image augmentation using rotation, intensity scaling,\n",
        "  flip and gamma correction.\n",
        "  Args:\n",
        "    img (numpy array): array of image pixels.\n",
        "    label (str): Label of the image.\n",
        "  Returns:\n",
        "    (numpy array): Augmented images.\n",
        "    (numpy array): Array of labels corresponding to the images.\n",
        "  \"\"\"\n",
        "  temp = [horizontal_flip(img), vertical_flip(img), random_rotation(img), gama(img), intensity(img)]\n",
        "  label = [label, label, label, label, label]\n",
        "  return temp, label\n",
        "\n",
        "\n",
        "def augment_data():\n",
        "  \"\"\"\n",
        "  Load the train data and augment loaded data.\n",
        "  \"\"\"\n",
        "  X_train = np.load(os.path.join(base_path, \"intermediate/imagetrain_input.npy\"))\n",
        "  y_train = np.load(os.path.join(base_path, \"intermediate/labeltrain_input.npy\"))\n",
        "  print(\"DATA TO BE AUGMENTED\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  as_count = br_count = ar_count = 0\n",
        "  transformed_image = []\n",
        "  labels = []\n",
        "\n",
        "  for i, name in enumerate(y_train):\n",
        "    if name == 'Apple healthy':\n",
        "      x, y = augment_image(X_train[i], name)\n",
        "      transformed_image.extend(x)\n",
        "      labels.extend(y)\n",
        "    elif name == 'Apple Apple scab':\n",
        "      x, y = augment_image(X_train[i], name)\n",
        "      transformed_image.extend(x)\n",
        "      labels.extend(y)\n",
        "      as_count += 1\n",
        "    elif name == 'Apple Black rot':\n",
        "      x, y = augment_image(X_train[i], name)\n",
        "      transformed_image.extend(x)\n",
        "      labels.extend(y)\n",
        "      br_count += 1    \n",
        "    elif name == 'Apple Cedar apple rust':\n",
        "      x, y = augment_image(X_train[i], name)\n",
        "      transformed_image.extend(x)\n",
        "      labels.extend(y)\n",
        "      ar_count += 1\n",
        "\n",
        "  transformed_image = np.array(transformed_image)\n",
        "  labels = np.array(labels)\n",
        "  print(\"AUGMENTED DATA\")\n",
        "  print(len(transformed_image))\n",
        "  print(len(labels))\n",
        "\n",
        "  # Concatenate with initial image array\n",
        "  X_train = np.concatenate((X_train, transformed_image), axis=0)\n",
        "  y_train = np.concatenate((y_train, labels), axis=0)\n",
        "  print(\"TOTAL MODEL INPUT DATA\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  # Save data\n",
        "  make_folder(os.path.join(base_path, \"augment\"))\n",
        "  np.save(os.path.join(base_path, \"augment/imageaugment_input.npy\"), X_train)\n",
        "  np.save(os.path.join(base_path, \"augment/labelaugment_input.npy\"), y_train)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8iHqM9Ejm2l"
      },
      "source": [
        "# SVM model\n",
        "def run_svm():\n",
        "  \"\"\"\n",
        "  Load the data. Train SVM model using linear kernel. Print accuracy on test dat.\n",
        "  \"\"\"\n",
        "  X_train = np.load(os.path.join(base_path, \"processed/imagetrainHOG_input.npy\"))\n",
        "  y_train = np.load(os.path.join(base_path, \"augment/labelaugment_input.npy\"))\n",
        "\n",
        "  print(\"=== TRAIN DATA ===\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  X_test = np.load(os.path.join(base_path, \"processed/imagetestHOG_input.npy\"))\n",
        "  y_test = np.load(os.path.join(base_path, \"test/labelstest_input.npy\"))\n",
        "\n",
        "  print(\"=== TEST DATA ===\")\n",
        "  print(len(X_test))\n",
        "  print(len(y_test))\n",
        "\n",
        "  svm_model = LinearSVC(dual=False)\n",
        "  svm_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  print(f\"SVM accuracy score {svm_model.score(X_test, y_test)}\")\n",
        "   \n",
        "  make_folder(os.path.join(base_path, \"results/models\"))\n",
        "  joblib.dump(svm_model, os.path.join(base_path, \"results/models/SVM_MODEL.sav\"))\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBChzQfcjznd"
      },
      "source": [
        "# Random Forest model\n",
        "def run_random_forest():\n",
        "  \"\"\"\n",
        "  Load the data. Train the model and print out the accuracy on test data\n",
        "  \"\"\"\n",
        "\n",
        "  X_train = np.load(os.path.join(base_path, \"processed/imagetrainHOG_input.npy\"))\n",
        "  y_train = np.load(os.path.join(base_path, \"augment/labelaugment_input.npy\"))\n",
        "  print(\"=== TRAIN DATA ===\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  X_test = np.load(os.path.join(base_path, \"processed/imagetestHOG_input.npy\"))\n",
        "  y_test = np.load(os.path.join(base_path, \"test/labelstest_input.npy\"))\n",
        "\n",
        "  print(\"=== TEST DATA ===\")\n",
        "  print(len(X_test))\n",
        "  print(len(y_test))\n",
        "\n",
        "  # Classifier\n",
        "  Random_classifier = RandomForestClassifier(n_estimators=500, max_depth=35,\n",
        "                                               n_jobs=-1, warm_start=True,\n",
        "                                               oob_score=True,\n",
        "                                               max_features='sqrt')\n",
        "  Random_classifier.fit(X_train, y_train)\n",
        "  print(f\"Random Forest accuracy score {Random_classifier.score(X_test, y_test)}\")\n",
        "\n",
        "  make_folder(os.path.join(base_path, \"results/models\"))\n",
        "  joblib.dump(Random_classifier, os.path.join(base_path, \"results/models/RANDOM_FOREST_MODEL.sav\"))\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRkkU50of2-Z"
      },
      "source": [
        "# KNeighbors classifier\n",
        "def run_kneighbors():\n",
        "  \"\"\"\n",
        "  Load the data. Train the model and print out the accuracy on test data\n",
        "  \"\"\"\n",
        "\n",
        "  X_train = np.load(os.path.join(base_path, \"processed/imagetrainHOG_input.npy\"))\n",
        "  y_train = np.load(os.path.join(base_path, \"augment/labelaugment_input.npy\"))\n",
        "  print(\"=== TRAIN DATA ===\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  X_test = np.load(os.path.join(base_path, \"processed/imagetestHOG_input.npy\"))\n",
        "  y_test = np.load(os.path.join(base_path, \"test/labelstest_input.npy\"))\n",
        "\n",
        "  print(\"=== TEST DATA ===\")\n",
        "  print(len(X_test))\n",
        "  print(len(y_test))\n",
        "\n",
        "  # Classifier\n",
        "  clf = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "  print(f\"K Neighbors accuracy score {clf.score(X_test, y_test)}\")\n",
        "\n",
        "  make_folder(os.path.join(base_path, \"results/models\"))\n",
        "  joblib.dump(clf, os.path.join(base_path, \"results/models/KNeighbors.sav\"))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WrEKEPWFRz8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152e0762-a1f3-485a-9c75-586c75ccafda"
      },
      "source": [
        "#Load the Images\n",
        "images, labels = load_dataset(colored_img_path, filenames)\n",
        "print('=== TOTAL DATA ===')\n",
        "print(len(labels))\n",
        "print(len(images))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== TOTAL DATA ===\n",
            "2336\n",
            "2336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4kwmmnyBI6V",
        "outputId": "c0e18409-28fe-4a0f-b8c4-27751c4a3f80"
      },
      "source": [
        "# Shuffle data\n",
        "images, labels = shuffle(images, labels, random_state=42)\n",
        "print(np.unique(labels))\n",
        "\n",
        "# Split train set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state= 42)\n",
        "\n",
        "print('=== TRAIN TEST SPLIT ===')\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Apple Apple scab' 'Apple Black rot' 'Apple Cedar apple rust'\n",
            " 'Apple healthy']\n",
            "=== TRAIN TEST SPLIT ===\n",
            "1868\n",
            "468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgkUk0pSFvxJ"
      },
      "source": [
        "# Save data\n",
        "base_path = '/content/drive/MyDrive/dataset'\n",
        "make_folder(os.path.join(base_path, \"test\"))\n",
        "make_folder(os.path.join(base_path, \"intermediate\"))\n",
        "np.save(os.path.join(base_path, \"test/imagetest_input.npy\"), X_test)\n",
        "np.save(os.path.join(base_path, \"test/labelstest_input.npy\"), y_test)\n",
        "np.save(os.path.join(base_path, \"intermediate/imagetrain_input.npy\"), X_train)\n",
        "np.save(os.path.join(base_path, \"intermediate/labeltrain_input.npy\"), y_train)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo-dG3sov5A1",
        "outputId": "40862c6b-aae1-4bc3-e1ba-ca9274738da8"
      },
      "source": [
        "augment_data()\n",
        "extract_feature()\n",
        "run_svm()\n",
        "run_random_forest()\n",
        "run_kneighbors()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATA TO BE AUGMENTED\n",
            "1868\n",
            "1868\n",
            "AUGMENTED DATA\n",
            "9340\n",
            "9340\n",
            "TOTAL MODEL INPUT DATA\n",
            "11208\n",
            "11208\n",
            "===TRAIN DATA===\n",
            "11208\n",
            "===TEST DATA===\n",
            "468\n",
            "Extracting HOG features...\n",
            "FEATURE DESCRIPTORS\n",
            "11208\n",
            "468\n",
            "=== TRAIN DATA ===\n",
            "11208\n",
            "11208\n",
            "=== TEST DATA ===\n",
            "468\n",
            "468\n",
            "SVM accuracy score 0.6153846153846154\n",
            "=== TRAIN DATA ===\n",
            "11208\n",
            "11208\n",
            "=== TEST DATA ===\n",
            "468\n",
            "468\n",
            "Random Forest accuracy score 0.7136752136752137\n",
            "=== TRAIN DATA ===\n",
            "11208\n",
            "11208\n",
            "=== TEST DATA ===\n",
            "468\n",
            "468\n",
            "K Neighbors accuracy score 0.6068376068376068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTl0lVICqpyN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}