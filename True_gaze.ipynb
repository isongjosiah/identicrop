{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "True_gaze.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X2mm9FdDRz8W"
      },
      "source": [
        "# Curbing crop loss in Nigeria's Agricultural Ecosystem\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdX_wBhbS4R8"
      },
      "source": [
        "About 690 million people are hungry today and three billion cannot afford a healthy diet [[1]](https://guardian.ng/apo-press-releases/food-loss-and-waste-must-be-reduced-for-greater-food-security-and-environmental-sustainability/) yet food continues to be wasted and lost. The status of global food security is alarming, and protection against losses caused by crop pests, plant diseases, in particular, can play a critical role in improving food security worldwide and meeting the growing demand for food quality and quantity. \n",
        "\n",
        "In this project, we process diseased and healthy apple crop images and build machine learning models that can help in the classification of diseased and healthy apple crops with plans to extend this implementation to all the crops in the Nigerian agricultural ecosystem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iKNHP96UlR4"
      },
      "source": [
        "#### Data and Goals\n",
        "We made use of the [PlantVillage dataset](https://www.kaggle.com/abdallahalidev/plantvillage-dataset)  dataset which at the time of this project contained 54,343 colored images of diseased and healthy images of the following crops:\n",
        "\n",
        "\n",
        "*   Apple\n",
        "*   Corn\n",
        "*   Grape\n",
        "*   Orange\n",
        "*   Peach\n",
        "*   Pepper\n",
        "*   Potato\n",
        "*   Raspberry\n",
        "*   Soybean\n",
        "*   Squash\n",
        "*   Strawberry\n",
        "*   Tomato\n",
        "\n",
        "However, for this project we trained our models on Apple crops only due to computation contraint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-CdDEQsWgei"
      },
      "source": [
        "#### Table of Content\n",
        "\n",
        "\n",
        "*   [Data Exploration](#data-exploration)\n",
        "*   [Data Preparation](#data-preparation)\n",
        "*   [Train Validation Test Split](#train-validation-test-split)\n",
        "*   [Data Augmentation](#data-augmentation)\n",
        "*   [Feature Extraction](#feature-extraction)\n",
        "*   [Supervised Learning](#supervised-learning)\n",
        "*   [Results](#results)\n",
        "*   [Exploration for future works](#exploration-for-future-works)\n",
        "*   [Conclusions](#conclusions)\n",
        "*   [Acknowledgements](#acknowledgements)\n",
        "*   [References](#references)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NYB9Vh9Rz8n"
      },
      "source": [
        "# utilities\n",
        "from skimage import util\n",
        "import joblib\n",
        "import os\n",
        "import random\n",
        "\n",
        "# data preprocessing and machine learning\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from skimage.transform import resize, rotate\n",
        "from skimage import exposure\n",
        "from skimage.feature import hog\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy import ndimage\n",
        "from skimage import io as skio\n",
        "from skimage import filters\n",
        "from scipy import misc\n",
        "\n",
        " "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLoyIQYQPA35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfoeA7CrlSrJ"
      },
      "source": [
        "# Global variables and utilities\n",
        "\n",
        "# Variables\n",
        "base_path = '/content/drive/MyDrive/dataset'\n",
        "filenames = sorted(os.listdir(base_path))\n",
        "\n",
        "\n",
        "# utilities\n",
        "def make_folder(path):\n",
        "  \"\"\" Check if a folder exists, if it doesn't exist create one in the given path\n",
        "  Args:\n",
        "    path [str]: path where the folder needs to be crerated\n",
        "  \"\"\"\n",
        "\n",
        "  if not os.path.exists(os.path.join(path)):\n",
        "    print(f'[INFO] Creating new folder {path}...')\n",
        "    os.makedirs(os.path.join(path))\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BL0Vy6nXp8p"
      },
      "source": [
        "<a name=\"data-preparation\"></a>\n",
        "## 1 Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGvAae0XYCHx"
      },
      "source": [
        "### 1.1 Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZRAurloN2iN"
      },
      "source": [
        "'''\r\n",
        "Gray images are resized to be of equal size and proportion, so as to reduce computation time.\r\n",
        "\r\n",
        "'''\r\n",
        "def remove_background(image_rgb):\r\n",
        "  height, width = image_rgb.shape[:2]\r\n",
        "\r\n",
        "  rectangle = (10,10,width-30,height-30)\r\n",
        "  # Create initial mask\r\n",
        "  mask = np.zeros(image_rgb.shape[:2], np.uint8)\r\n",
        "\r\n",
        "  # Create temporary arrays used by grabCut\r\n",
        "  bgdModel = np.zeros((1, 65), np.float64)\r\n",
        "  fgdModel = np.zeros((1, 65), np.float64)\r\n",
        "\r\n",
        "  # Run grabCut\r\n",
        "  cv2.grabCut(image_rgb, # Our image\r\n",
        "              mask, # The Mask\r\n",
        "              rectangle, # Our rectangle\r\n",
        "              bgdModel, # Temporary array for background\r\n",
        "              fgdModel, # Temporary array for background\r\n",
        "              5, # Number of iterations\r\n",
        "              cv2.GC_INIT_WITH_RECT) # Initiative using our rectangle\r\n",
        "\r\n",
        "  # Create mask where sure and likely backgrounds set to 0, otherwise 1\r\n",
        "  mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\r\n",
        "\r\n",
        "  # Multiply image with new mask to subtract background\r\n",
        "  image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]\r\n",
        "\r\n",
        "  return image_rgb_nobg"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0etG7umlWRzF"
      },
      "source": [
        "# Image processing code\n",
        "def resize_image(image):\n",
        "  \"\"\"\n",
        "  Resizes the image to a 100 by 100.\n",
        "  Args:\n",
        "    image (numpy array): Array of image pixels.\n",
        "\n",
        "  Returns:\n",
        "    (numpy array): Resized image\n",
        "  \"\"\"\n",
        "  image = resize(image, (100,100))\n",
        "  return image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDcpWyW0dCxm"
      },
      "source": [
        "def threshold(image, value):\r\n",
        "  image = image > value\r\n",
        "  return image\r\n",
        "\r\n",
        "def get_threshold_image(image):\r\n",
        "\r\n",
        "  #converts image np array to grey scale\r\n",
        "  r, g, b = image[:,:,0], image[:,:,1], image[:,:,2]\r\n",
        "  gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\r\n",
        "  i = np.dot(image[...,:3], [0.299, 0.587, 0.114])\r\n",
        "\r\n",
        "  im_th = threshold(i, 0.2)\r\n",
        "  \r\n",
        "  new_image = util.img_as_ubyte(im_th, force_copy=False)\r\n",
        "\r\n",
        "  filled_image = ndimage.binary_fill_holes(new_image)\r\n",
        "  \r\n",
        "  return new_image\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0rZLUvma6fH"
      },
      "source": [
        "def process_images(image):\n",
        "  # image_bgr = cv2.imread(image_path)\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_no_bgr = remove_background(image_rgb)\n",
        "  resized_image = resize_image(image_no_bgr)\n",
        "  image_thresh = get_threshold_image(resized_image)\n",
        "\n",
        "  return image_thresh"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJjAvQSqYP_z"
      },
      "source": [
        "### 1.2 Load images and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU6dythUeUeb"
      },
      "source": [
        "In order to use the images in training the machine learning model we had to load and label the images. As these images were not labelled from source we had to devise how to link a label to a particular image. \n",
        "\n",
        "Two arrays were created; One to hold the images and the other to hold the label of these images. \n",
        "The images stored into the array undergo preprocessing before they are stored in the array, so that images in the array are ready for subsequent steps of the pipeline.\n",
        "\n",
        "so when an image is loaded, the label is also loaded. This means that an image in position i of the image array has it's label in position i of the label array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lGWNkjLkRz8v"
      },
      "source": [
        "def get_image_path(path, foldername=\"\"):\n",
        "    \"\"\"\n",
        "    The function reads images from a location, specified by the path returning an array containing the images in that\n",
        "    location\n",
        "    :param path: the location of the data.\n",
        "    :param foldername: this by default is an empty string but can be used if the path contains multiple folders you\n",
        "    you can then parse using a for loop and changing the value of the parameter at every iteration\n",
        "    :return: an array of images in the path/filename directory\n",
        "    \"\"\"\n",
        "    images = sorted([os.path.join(path, foldername, file) for file in os.listdir(os.path.join(path, foldername))])\n",
        "    return images\n",
        "\n",
        "\n",
        "def get_label(file_name):\n",
        "  label = file_name.replace(\"___\", \" \")\n",
        "  label = label.replace(\"_\", \" \")\n",
        "  return label\n",
        "\n",
        "\n",
        "def load_dataset(path, filenames):\n",
        "    \"\"\"\n",
        "    load_dataset loads all of the images in the plantvillage dataset storing them in a dictionary with keys representing\n",
        "    the foldernames and the values are arrays containing the images in the folder\n",
        "    :param path: the location of the data\n",
        "    :param filenames: a list of the folders in the path. This can be obtained by running sorted(os.listdir(path))\n",
        "    :return: a dictionary with keys identifying the crops and diseased state(healthy or the type of diseases)and values\n",
        "    which are arrays containing the images in that folder\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    for i in filenames:\n",
        "        # Ignore ipynb checkpoints and any other plant except apple\n",
        "        if i == '.ipynb_checkpoints' or \"Apple\" not in i :\n",
        "          continue\n",
        "        img_arr = get_image_path(path, i)\n",
        "        for img in img_arr:\n",
        "          img = plt.imread(img)\n",
        "          img = process_images(img)\n",
        "          images.append(img)\n",
        "          labels.append(get_label(i))\n",
        "    img_arr = np.array(images)\n",
        "    label_arr = np.array(labels)\n",
        "          \n",
        "    return images,labels"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE7wa7oJYcOI"
      },
      "source": [
        "<a name=\"feature-extraction\"></a>\n",
        "## 2 Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY-nmxWr5pCf"
      },
      "source": [
        "def hog_feature(image):\r\n",
        "  \"\"\"\r\n",
        "  Extract HOG feature descriptors from the image\r\n",
        "\r\n",
        "  Args: \r\n",
        "    image (numpy array): Array of image pixels.\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    (numpy array): Feature descriptors\r\n",
        "  \"\"\"\r\n",
        "  return hog(image)\r\n",
        "\r\n",
        "def extract_feature():\r\n",
        "  \"\"\"\r\n",
        "  Load images and extract HOG feature desscriptors.\r\n",
        "  \"\"\"\r\n",
        "  X_train = np.load(os.path.join(base_path, \"augment/imageaugment_input.npy\"))\r\n",
        "  print(\"===TRAIN DATA===\")\r\n",
        "  print(len(X_train))\r\n",
        "  print(X_train.shape)\r\n",
        "\r\n",
        "  X_test = np.load(os.path.join(base_path, \"test/imagetest_input.npy\"))\r\n",
        "  print(\"===TEST DATA===\")\r\n",
        "  print(len(X_test))\r\n",
        "  print(X_test.shape)\r\n",
        "\r\n",
        "  print(\"Extracting HOG features...\")\r\n",
        "  RF_train = np.zeros([len(X_train), 8100])\r\n",
        "  for i in range(len(X_train)):\r\n",
        "    RF_train[i] = hog_feature(X_train[i])\r\n",
        "  print(\"FEATURE DESCRIPTORS\")\r\n",
        "  print(len(RF_train))\r\n",
        "\r\n",
        "  RF_test = np.zeros([len(X_test), 8100])\r\n",
        "  for i in range(len(X_test)):\r\n",
        "    RF_test[i] = hog_feature(X_test[i])\r\n",
        "  print(len(RF_test))\r\n",
        "\r\n",
        "  # Save data\r\n",
        "  make_folder(os.path.join(base_path, \"processed\"))\r\n",
        "  np.save(os.path.join(base_path, \"processed/imagetrainHOG_input.npy\"), RF_train)\r\n",
        "  np.save(os.path.join(base_path, \"processed/imagetestHOG_input.npy\"), RF_test)\r\n",
        "\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EquAwaflYjF7"
      },
      "source": [
        "<a name=\"data-augmentation\"></a>\n",
        "## 3 Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbLY4uvvJCuq"
      },
      "source": [
        "# Data Augmentation\n",
        "def random_rotation(img):\n",
        "  \"\"\"\n",
        "  Randomly rotate the image.\n",
        "  The function picks a random degree of rotation between 25% on the \n",
        "  left and 25% on the right\n",
        "\n",
        "  Args:\n",
        "    img (numpy array): Array of image pixel to rotate\n",
        "\n",
        "  Returns:\n",
        "    (numpy array): Rotated image.\n",
        "  \"\"\"\n",
        "  random_deg = random.uniform(-25, 25)\n",
        "  return rotate(img, random_deg, preserve_range=True).astype(np.uint8)\n",
        "\n",
        "def horizontal_flip(img):\n",
        "  \"\"\"\n",
        "  Flip the image horizontally\n",
        "  Args:\n",
        "    img (numpy array): Array of image pixels.\n",
        "\n",
        "  Returns:\n",
        "    (numpy array): Flipped image.\n",
        "  \"\"\"\n",
        "  return np.fliplr(img)\n",
        "\n",
        "def vertical_flip(img):\n",
        "  \"\"\"\n",
        "  Flip the image vertically\n",
        "  Args:\n",
        "    img (numpy array): Array of image pixels\n",
        "  Returns:\n",
        "    (numpy array): Flipped image.\n",
        "  \"\"\"\n",
        "  return np.flipud(img)\n",
        "\n",
        "def gama(img):\n",
        "  \"\"\"\n",
        "  Perform gamma correction of the image\n",
        "\n",
        "  Args:\n",
        "    img (numpy arrayy): Array of image pixes\n",
        "\n",
        "  Returns:\n",
        "    (numpy array): Enhanced image.\n",
        "  \"\"\"\n",
        "  return exposure.adjust_gamma(img, gamma=0.4, gain=0.9)\n",
        "\n",
        "\n",
        "def intensity(img):\n",
        "    \"\"\" \n",
        "    Change the intensity of the image.\n",
        "    Args:\n",
        "        img (numpy array): Array of image pixels.\n",
        "    Returns:\n",
        "        (numpy array): Enhanced image.\n",
        "    \"\"\"\n",
        "    v_min, v_max = np.percentile(img, (0.2, 99.8))\n",
        "    if np.abs(v_max - v_min) < 1e-3:\n",
        "        v_max += 1e-3\n",
        "    return exposure.rescale_intensity(img, in_range=(v_min, v_max))\n",
        "\n",
        "def augment_image(img, label):\n",
        "  \"\"\"\n",
        "  Performs image augmentation using rotation, intensity scaling,\n",
        "  flip and gamma correction.\n",
        "  Args:\n",
        "    img (numpy array): array of image pixels.\n",
        "    label (str): Label of the image.\n",
        "  Returns:\n",
        "    (numpy array): Augmented images.\n",
        "    (numpy array): Array of labels corresponding to the images.\n",
        "  \"\"\"\n",
        "  temp = [horizontal_flip(img), vertical_flip(img), random_rotation(img), gama(img), intensity(img)]\n",
        "  label = [label, label, label, label, label]\n",
        "  return temp, label\n",
        "\n",
        "\n",
        "def augment_data():\n",
        "  \"\"\"\n",
        "  Load the train data and augment loaded data.\n",
        "  \"\"\"\n",
        "  X_train = np.load(os.path.join(base_path, \"intermediate/imagetrain_input.npy\"))\n",
        "  y_train = np.load(os.path.join(base_path, \"intermediate/labeltrain_input.npy\"))\n",
        "  print(\"DATA TO BE AUGMENTED\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  as_count = br_count = ar_count = 0\n",
        "  transformed_image = []\n",
        "  labels = []\n",
        "\n",
        "  for i, name in enumerate(y_train):\n",
        "    if name == 'Apple healthy':\n",
        "      x, y = augment_image(X_train[i], name)\n",
        "      transformed_image.extend(x)\n",
        "      labels.extend(y)\n",
        "    elif name == 'Apple Apple scab':\n",
        "      x, y = augment_image(X_train[i], name)\n",
        "      transformed_image.extend(x)\n",
        "      labels.extend(y)\n",
        "      as_count += 1\n",
        "    elif name == 'Apple Black rot':\n",
        "      x, y = augment_image(X_train[i], name)\n",
        "      transformed_image.extend(x)\n",
        "      labels.extend(y)\n",
        "      br_count += 1    \n",
        "    elif name == 'Apple Cedar apple rust':\n",
        "      x, y = augment_image(X_train[i], name)\n",
        "      transformed_image.extend(x)\n",
        "      labels.extend(y)\n",
        "      ar_count += 1\n",
        "\n",
        "  transformed_image = np.array(transformed_image)\n",
        "  labels = np.array(labels)\n",
        "  print(\"AUGMENTED DATA\")\n",
        "  print(len(transformed_image))\n",
        "  print(len(labels))\n",
        "\n",
        "  # Concatenate with initial image array\n",
        "  X_train = np.concatenate((X_train, transformed_image), axis=0)\n",
        "  y_train = np.concatenate((y_train, labels), axis=0)\n",
        "  print(\"TOTAL MODEL INPUT DATA\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  # Save data\n",
        "  make_folder(os.path.join(base_path, \"augment\"))\n",
        "  np.save(os.path.join(base_path, \"augment/imageaugment_input.npy\"), X_train)\n",
        "  np.save(os.path.join(base_path, \"augment/labelaugment_input.npy\"), y_train)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsppNKRfYtCo"
      },
      "source": [
        "<a name=\"supervised-learning\"></a>\n",
        "## 4 Supervised Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CKkLpATY7Be"
      },
      "source": [
        "### 4.1 Classification Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8iHqM9Ejm2l"
      },
      "source": [
        "# SVM model\n",
        "def run_svm():\n",
        "  \"\"\"\n",
        "  Load the data. Train SVM model using linear kernel. Print accuracy on test dat.\n",
        "  \"\"\"\n",
        "  X_train = np.load(os.path.join(base_path, \"processed/imagetrainHOG_input.npy\"))\n",
        "  y_train = np.load(os.path.join(base_path, \"augment/labelaugment_input.npy\"))\n",
        "\n",
        "  print(\"=== TRAIN DATA ===\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  X_test = np.load(os.path.join(base_path, \"processed/imagetestHOG_input.npy\"))\n",
        "  y_test = np.load(os.path.join(base_path, \"test/labelstest_input.npy\"))\n",
        "\n",
        "  print(\"=== TEST DATA ===\")\n",
        "  print(len(X_test))\n",
        "  print(len(y_test))\n",
        "\n",
        "  svm_model = LinearSVC(dual=False)\n",
        "  svm_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  print(f\"SVM accuracy score {svm_model.score(X_test, y_test)}\")\n",
        "   \n",
        "  make_folder(os.path.join(base_path, \"results/models\"))\n",
        "  joblib.dump(svm_model, os.path.join(base_path, \"results/models/SVM_MODEL.sav\"))\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBChzQfcjznd"
      },
      "source": [
        "# Random Forest model\n",
        "def run_random_forest():\n",
        "  \"\"\"\n",
        "  Load the data. Train the model and print out the accuracy on test data\n",
        "  \"\"\"\n",
        "\n",
        "  X_train = np.load(os.path.join(base_path, \"processed/imagetrainHOG_input.npy\"))\n",
        "  y_train = np.load(os.path.join(base_path, \"augment/labelaugment_input.npy\"))\n",
        "  print(\"=== TRAIN DATA ===\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  X_test = np.load(os.path.join(base_path, \"processed/imagetestHOG_input.npy\"))\n",
        "  y_test = np.load(os.path.join(base_path, \"test/labelstest_input.npy\"))\n",
        "\n",
        "  print(\"=== TEST DATA ===\")\n",
        "  print(len(X_test))\n",
        "  print(len(y_test))\n",
        "\n",
        "  # Classifier\n",
        "  Random_classifier = RandomForestClassifier(n_estimators=500, max_depth=35,\n",
        "                                               n_jobs=-1, warm_start=True,\n",
        "                                               oob_score=True,\n",
        "                                               max_features='sqrt')\n",
        "  Random_classifier.fit(X_train, y_train)\n",
        "  print(f\"Random Forest accuracy score {Random_classifier.score(X_test, y_test)}\")\n",
        "\n",
        "  make_folder(os.path.join(base_path, \"results/models\"))\n",
        "  joblib.dump(Random_classifier, os.path.join(base_path, \"results/models/RANDOM_FOREST_MODEL.sav\"))\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRkkU50of2-Z"
      },
      "source": [
        "# KNeighbors classifier\n",
        "def run_kneighbors():\n",
        "  \"\"\"\n",
        "  Load the data. Train the model and print out the accuracy on test data\n",
        "  \"\"\"\n",
        "\n",
        "  X_train = np.load(os.path.join(base_path, \"processed/imagetrainHOG_input.npy\"))\n",
        "  y_train = np.load(os.path.join(base_path, \"augment/labelaugment_input.npy\"))\n",
        "  print(\"=== TRAIN DATA ===\")\n",
        "  print(len(X_train))\n",
        "  print(len(y_train))\n",
        "\n",
        "  X_test = np.load(os.path.join(base_path, \"processed/imagetestHOG_input.npy\"))\n",
        "  y_test = np.load(os.path.join(base_path, \"test/labelstest_input.npy\"))\n",
        "\n",
        "  print(\"=== TEST DATA ===\")\n",
        "  print(len(X_test))\n",
        "  print(len(y_test))\n",
        "\n",
        "  # Classifier\n",
        "  clf = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "  clf.fit(X_train, y_train)\n",
        "  print(f\"K Neighbors accuracy score {clf.score(X_test, y_test)}\")\n",
        "\n",
        "  make_folder(os.path.join(base_path, \"results/models\"))\n",
        "  joblib.dump(clf, os.path.join(base_path, \"results/models/KNeighbors.sav\"))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BO6oFyqYxlC"
      },
      "source": [
        "### 4.2 Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUaTHdwxkBiU"
      },
      "source": [
        "# Predict single image\n",
        "def predict(img):\n",
        "  \"\"\"\n",
        "  Predict the classification of a single image\n",
        "  Args:\n",
        "    img(numpy array)\n",
        "  Returns:\n",
        "    (string) label for images\n",
        "  \"\"\"\n",
        "  # take the image through preprocessing\n",
        "  img = plt.imread(img)\n",
        "  img = process_images(img)\n",
        "  img = np.array(img)\n",
        "  img = hog_feature(img)\n",
        "  \n",
        "  img = img.reshape(1, -1)\n",
        "\n",
        "  # load the models\n",
        "  svm_model = joblib.load(os.path.join(base_path, \"results/models/SVM_MODEL.sav\"))\n",
        "  rfc_model = joblib.load(os.path.join(base_path, \"results/models/RANDOM_FOREST_MODEL.sav\"))\n",
        "  knn_model = joblib.load(os.path.join(base_path, \"results/models/KNeighbors.sav\"))\n",
        "\n",
        "  # Predict\n",
        "  svm_label = svm_model.predict(img)\n",
        "  rfc_label = rfc_model.predict(img)\n",
        "  knn_label = knn_model.predict(img)\n",
        "\n",
        "  print(f\"SVM Classifier predicts {svm_label}\")\n",
        "  print(f\"Random Forest Classifier predicts {rfc_label}\")\n",
        "  print(f\"KNN predicts {knn_label}\")\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WrEKEPWFRz8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c933f11a-8536-4759-a251-ca2d4ca3f0e8"
      },
      "source": [
        "#Load the Images\n",
        "images, labels = load_dataset(base_path, filenames)\n",
        "print('=== TOTAL DATA ===')\n",
        "print(len(labels))\n",
        "print(len(images))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== TOTAL DATA ===\n",
            "2336\n",
            "2336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGuAn_wNZKan"
      },
      "source": [
        "<a name=\"train-validation-test-split\"></a>\n",
        "## 5 Train Validation Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4kwmmnyBI6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3721ddf3-c72d-49e7-eedd-d7e3f0e9c19a"
      },
      "source": [
        "# Shuffle data\n",
        "images, labels = shuffle(images, labels, random_state=42)\n",
        "print(np.unique(labels))\n",
        "\n",
        "# Split train set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state= 42)\n",
        "\n",
        "print('=== TRAIN TEST SPLIT ===')\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Apple Apple scab' 'Apple Black rot' 'Apple Cedar apple rust'\n",
            " 'Apple healthy']\n",
            "=== TRAIN TEST SPLIT ===\n",
            "1868\n",
            "468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgkUk0pSFvxJ"
      },
      "source": [
        "# Save data\n",
        "base_path = '/content/drive/MyDrive/dataset'\n",
        "make_folder(os.path.join(base_path, \"test\"))\n",
        "make_folder(os.path.join(base_path, \"intermediate\"))\n",
        "np.save(os.path.join(base_path, \"test/imagetest_input.npy\"), X_test)\n",
        "np.save(os.path.join(base_path, \"test/labelstest_input.npy\"), y_test)\n",
        "np.save(os.path.join(base_path, \"intermediate/imagetrain_input.npy\"), X_train)\n",
        "np.save(os.path.join(base_path, \"intermediate/labeltrain_input.npy\"), y_train)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQtWZwrDZXbU"
      },
      "source": [
        "<a name=\"results\"></a>\n",
        "## 6 Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo-dG3sov5A1",
        "outputId": "2178aa3b-7541-43c1-d104-a6b4a559e9a3"
      },
      "source": [
        "augment_data()\n",
        "extract_feature()\n",
        "run_svm()\n",
        "run_random_forest()\n",
        "run_kneighbors()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATA TO BE AUGMENTED\n",
            "1868\n",
            "1868\n",
            "AUGMENTED DATA\n",
            "9340\n",
            "9340\n",
            "TOTAL MODEL INPUT DATA\n",
            "11208\n",
            "11208\n",
            "===TRAIN DATA===\n",
            "11208\n",
            "(11208, 100, 100)\n",
            "===TEST DATA===\n",
            "468\n",
            "(468, 100, 100)\n",
            "Extracting HOG features...\n",
            "FEATURE DESCRIPTORS\n",
            "11208\n",
            "468\n",
            "=== TRAIN DATA ===\n",
            "11208\n",
            "11208\n",
            "=== TEST DATA ===\n",
            "468\n",
            "468\n",
            "SVM accuracy score 0.6175213675213675\n",
            "=== TRAIN DATA ===\n",
            "11208\n",
            "11208\n",
            "=== TEST DATA ===\n",
            "468\n",
            "468\n",
            "Random Forest accuracy score 0.7200854700854701\n",
            "=== TRAIN DATA ===\n",
            "11208\n",
            "11208\n",
            "=== TEST DATA ===\n",
            "468\n",
            "468\n",
            "K Neighbors accuracy score 0.6111111111111112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTl0lVICqpyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c22fdb4-43f7-4696-b666-739ec6cb5eb9"
      },
      "source": [
        "predict(\"/content/drive/MyDrive/dataset/Apple___Apple_scab/00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Classifier predicts ['Apple Apple scab']\n",
            "Random Forest Classifier predicts ['Apple Apple scab']\n",
            "KNN predicts ['Apple Apple scab']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7savt6AZj2R"
      },
      "source": [
        "<a name=\"exploration-for-future-works\"></a>\n",
        "## 7 Exploration for future works\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFMsUjfoZrJn"
      },
      "source": [
        "<a name=\"conclusions\"></a>\n",
        "## 8 Conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-efmEKAYZt_H"
      },
      "source": [
        "<a name=\"acknowledgements\"></a>\n",
        "## 9 Acknowledgements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YJCy8GxZ5Jr"
      },
      "source": [
        "<a name=\"references\"></a>\n",
        "## 10 References"
      ]
    }
  ]
}